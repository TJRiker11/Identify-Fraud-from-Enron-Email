{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Fraud from Enron Email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. This project is to build a person of interest identifier based on financial and email data made public as a result of the Enron scandal.\n",
    "\n",
    "> A Person of Interest(PoI) is an individual who meets one of the following criteria:\n",
    ">* Individuals who were indicted\n",
    ">* Individuals who reached a settlement or plea deal with the government\n",
    ">* Individuals who testified in exchange for prosecution immunity.\n",
    "\n",
    "> The full project and all data for this project can be seen in [this Github repository](https://github.com/TrikerDev/Identify-Fraud-from-Enron-Email). Data such as financial records, emails from employees, PoI names, etc, can be seen [here](https://github.com/TrikerDev/Identify-Fraud-from-Enron-Email/tree/master/Identify%20Fraud%20from%20Enron%20Email/Enron%20Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"Enron Data/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "with open(\"Enron Data/final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of executives in the dataset\n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This shows that there are 146 executives in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['METTS MARK', 'BAXTER JOHN C', 'ELLIOTT STEVEN', 'CORDES WILLIAM R', 'HANNON KEVIN P', 'MORDAUNT KRISTINA M', 'MEYER ROCKFORD G', 'MCMAHON JEFFREY', 'HORTON STANLEY C', 'PIPER GREGORY F', 'HUMPHREY GENE E', 'UMANOFF ADAM S', 'BLACHMAN JEREMY M', 'SUNDE MARTIN', 'GIBBS DANA R', 'LOWRY CHARLES P', 'COLWELL WESLEY', 'MULLER MARK S', 'JACKSON CHARLENE R', 'WESTFAHL RICHARD K', 'WALTERS GARETH W', 'WALLS JR ROBERT H', 'KITCHEN LOUISE', 'CHAN RONNIE', 'BELFER ROBERT', 'SHANKMAN JEFFREY A', 'WODRASKA JOHN', 'BERGSIEKER RICHARD P', 'URQUHART JOHN A', 'BIBI PHILIPPE A', 'RIEKER PAULA H', 'WHALEY DAVID A', 'BECK SALLY W', 'HAUG DAVID L', 'ECHOLS JOHN B', 'MENDELSOHN JOHN', 'HICKERSON GARY J', 'CLINE KENNETH W', 'LEWIS RICHARD', 'HAYES ROBERT E', 'MCCARTY DANNY J', 'KOPPER MICHAEL J', 'LEFF DANIEL P', 'LAVORATO JOHN J', 'BERBERIAN DAVID', 'DETMERING TIMOTHY J', 'WAKEHAM JOHN', 'POWERS WILLIAM', 'GOLD JOSEPH', 'BANNANTINE JAMES M', 'DUNCAN JOHN H', 'SHAPIRO RICHARD S', 'SHERRIFF JOHN R', 'SHELBY REX', 'LEMAISTRE CHARLES', 'DEFFNER JOSEPH M', 'KISHKILL JOSEPH G', 'WHALLEY LAWRENCE G', 'MCCONNELL MICHAEL S', 'PIRO JIM', 'DELAINEY DAVID W', 'SULLIVAN-SHAKLOVITZ COLLEEN', 'WROBEL BRUCE', 'LINDHOLM TOD A', 'MEYER JEROME J', 'LAY KENNETH L', 'BUTTS ROBERT H', 'OLSON CINDY K', 'MCDONALD REBECCA', 'CUMBERLAND MICHAEL S', 'GAHN ROBERT S', 'MCCLELLAN GEORGE', 'HERMANN ROBERT J', 'SCRIMSHAW MATTHEW', 'GATHMANN WILLIAM D', 'HAEDICKE MARK E', 'BOWEN JR RAYMOND M', 'GILLIS JOHN', 'FITZGERALD JAY L', 'MORAN MICHAEL P', 'REDMOND BRIAN L', 'BAZELIDES PHILIP J', 'BELDEN TIMOTHY N', 'DURAN WILLIAM D', 'THORN TERENCE H', 'FASTOW ANDREW S', 'FOY JOE', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'KAMINSKI WINCENTY J', 'LOCKHART EUGENE E', 'COX DAVID', 'OVERDYKE JR JERE C', 'PEREIRA PAULO V. FERRAZ', 'STABLER FRANK', 'SKILLING JEFFREY K', 'BLAKE JR. NORMAN P', 'SHERRICK JEFFREY B', 'PRENTICE JAMES', 'GRAY RODNEY', 'PICKERING MARK R', 'THE TRAVEL AGENCY IN THE PARK', 'NOLES JAMES L', 'KEAN STEVEN J', 'TOTAL', 'FOWLER PEGGY', 'WASAFF GEORGE', 'WHITE JR THOMAS E', 'CHRISTODOULOU DIOMEDES', 'ALLEN PHILLIP K', 'SHARP VICTORIA T', 'JAEDICKE ROBERT', 'WINOKUR JR. HERBERT S', 'BROWN MICHAEL', 'BADUM JAMES P', 'HUGHES JAMES A', 'REYNOLDS LAWRENCE', 'DIMICHELE RICHARD G', 'BHATNAGAR SANJAY', 'CARTER REBECCA C', 'BUCHANAN HAROLD G', 'YEAP SOON', 'MURRAY JULIA H', 'GARLAND C KEVIN', 'DODSON KEITH', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'DIETRICH JANET R', 'DERRICK JR. JAMES V', 'FREVERT MARK A', 'PAI LOU L', 'BAY FRANKLIN R', 'HAYSLETT RODERICK J', 'FUGH JOHN L', 'FALLON JAMES B', 'KOENIG MARK E', 'SAVAGE FRANK', 'IZZO LAWRENCE L', 'TILNEY ELIZABETH A', 'MARTIN AMANDA K', 'BUY RICHARD B', 'GRAMM WENDY L', 'CAUSEY RICHARD A', 'TAYLOR MITCHELL S', 'DONAHUE JR JEFFREY M', 'GLISAN JR BEN F']\n"
     ]
    }
   ],
   "source": [
    "# The names of the executives\n",
    "print data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is the names of all 146 executives in the dataset. Scanning over it, we can see that there are many names, but also several names that dont really make sense in this context. These will be taken care of in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 person of interest.\n",
      "['HANNON KEVIN P', 'COLWELL WESLEY', 'RIEKER PAULA H', 'KOPPER MICHAEL J', 'SHELBY REX', 'DELAINEY DAVID W', 'LAY KENNETH L', 'BOWEN JR RAYMOND M', 'BELDEN TIMOTHY N', 'FASTOW ANDREW S', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'SKILLING JEFFREY K', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'KOENIG MARK E', 'CAUSEY RICHARD A', 'GLISAN JR BEN F']\n"
     ]
    }
   ],
   "source": [
    "# count people of interest\n",
    "count_poi = 0\n",
    "poi_name = []\n",
    "for entry in data_dict:\n",
    "    if data_dict[entry]['poi'] == 1:\n",
    "        count_poi += 1\n",
    "        poi_name.append(entry)\n",
    "print \"There are \" + str(count_poi) + \" person of interest.\"\n",
    "print poi_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This shows that there are 18 total people of interest and the names of those individuals. This also means that since there are 146 total people, and only 18 of them are PoIs, then there are 128 individuals who are not a person of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Right away, we can see some outliers in this dataset. The first is 'THE TRAVEL AGENCY IN THE PARK'. This is supposed to be a list of the names of executives, so this is clearly in the wrong place. Another outlier is 'TOTAL'. This 'TOTAL' data is the sum of all other executives. We dont want the total of every person on the list, so this is an outlier that will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing THE TRAVEL AGENCY IN THE PARK outlier\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing TOTAL outlier\n",
    "data_dict.pop('TOTAL', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another way to find potential outliers is to find individuals who may have Total Payments as NaN. This could potentially mean that this person should not be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORDES WILLIAM R\n",
      "LOWRY CHARLES P\n",
      "CHAN RONNIE\n",
      "WHALEY DAVID A\n",
      "CLINE KENNETH W\n",
      "LEWIS RICHARD\n",
      "MCCARTY DANNY J\n",
      "POWERS WILLIAM\n",
      "PIRO JIM\n",
      "WROBEL BRUCE\n",
      "MCDONALD REBECCA\n",
      "SCRIMSHAW MATTHEW\n",
      "GATHMANN WILLIAM D\n",
      "GILLIS JOHN\n",
      "MORAN MICHAEL P\n",
      "LOCKHART EUGENE E\n",
      "SHERRICK JEFFREY B\n",
      "FOWLER PEGGY\n",
      "CHRISTODOULOU DIOMEDES\n",
      "HUGHES JAMES A\n",
      "HAYSLETT RODERICK J\n"
     ]
    }
   ],
   "source": [
    "# List of people with no total payment data\n",
    "for entry in data_dict:\n",
    "    if data_dict[entry]['total_payments'] == 'NaN':\n",
    "        print entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This could be narrowed down further by adding another main criteria to the list: the stock options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAN RONNIE\n",
      "POWERS WILLIAM\n",
      "LOCKHART EUGENE E\n"
     ]
    }
   ],
   "source": [
    "# List of people with no total payment data and no stock option data\n",
    "for entry in data_dict:\n",
    "    if data_dict[entry]['total_payments'] == 'NaN' and data_dict[entry]['total_stock_value'] == 'NaN':\n",
    "        print entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Investigating these individuals, we can see that they are missing lots of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': -98784,\n",
       " 'director_fees': 98784,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 32460,\n",
       " 'restricted_stock_deferred': -32460,\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating CHAN RONNIE\n",
    "data_dict['CHAN RONNIE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': -17500,\n",
       " 'director_fees': 17500,\n",
       " 'email_address': 'ken.powers@enron.com',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 26,\n",
       " 'from_poi_to_this_person': 0,\n",
       " 'from_this_person_to_poi': 0,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 12,\n",
       " 'to_messages': 653,\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating POWERS WILLIAM\n",
    "data_dict['POWERS WILLIAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating LOCKHART EUGENE E\n",
    "data_dict['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LOCKHART EUGENE E is the most obvious outlier here, as this individual has NaN for every feature, and he is also not a PoI. This is an outlier that will be removed.\n",
    "\n",
    "> CHAN RONNIE is also an outlier, as he as NaN for most features and is not a PoI. The features he does have are payments and stock. However, these are both cancelled out to zero as they are deferred for the exact same amount. This leaves us with another blank slate. This outlier will be removed.\n",
    "\n",
    "> POWERS WILLIAM does have NaN and 0 for many of the features, however he does have several features that the other two did not have, such as messages and receipts. This gives up more information that can be used in the investigation. So even though much information is missing, we can still gather some data from this individual. This is not an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing LOCKHART EUGENE E outlier\n",
    "data_dict.pop('LOCKHART EUGENE E', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': -98784,\n",
       " 'director_fees': 98784,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 32460,\n",
       " 'restricted_stock_deferred': -32460,\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing CHAN RONNIE outlier\n",
    "data_dict.pop('CHAN RONNIE', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this new dataset without the outliers\n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this section we are going to create a new feature to add to the feature list. The original features will be put into a list below, and then a new feature will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "# Printing all features\n",
    "print len((my_dataset['SKILLING JEFFREY K'].keys()))\n",
    "print (my_dataset['SKILLING JEFFREY K'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that there are 21 original features. We are going to add these into a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of original features\n",
    "features_list = [\n",
    " 'poi',\n",
    " 'bonus',\n",
    " 'deferral_payments',\n",
    " 'deferred_income',\n",
    " 'director_fees',\n",
    " 'email_address',\n",
    " 'exercised_stock_options',\n",
    " 'expenses',\n",
    " 'from_messages',\n",
    " 'from_poi_to_this_person',\n",
    " 'from_this_person_to_poi',\n",
    " 'loan_advances',\n",
    " 'long_term_incentive',\n",
    " 'other',\n",
    " 'restricted_stock',\n",
    " 'restricted_stock_deferred',\n",
    " 'salary',\n",
    " 'shared_receipt_with_poi',\n",
    " 'to_messages',\n",
    " 'total_payments',\n",
    " 'total_stock_value'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The new feature we will create will be a cross between 'from_poi_to_this_person' and 'from_this_person_to_poi'. The theory is that a PoI would potentially have many more emails to and from other PoIs, whereas non PoIs would probably communicate less to PoIs. \n",
    "\n",
    "> We will create this new feature by adding the 'from_poi_to_this_person' and 'from_this_person_to_poi' together to get the total amount of PoI emails. We will then add 'to_messages' and 'from_messages' together to get the total amount of emails in general. Then dividing PoI emails by Total emails, we can get the percentage of communication between PoIs and Non-PoIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new list by adding two lists together\n",
    "def get_total_list(list1, list2):\n",
    "    new_list = []\n",
    "    for i in my_dataset:\n",
    "        if my_dataset[i][list1] == 'NaN' or my_dataset[i][list2] == 'NaN':\n",
    "            new_list.append(0.)\n",
    "        elif my_dataset[i][list1]>=0:\n",
    "            new_list.append(float(my_dataset[i][list1]) + float(my_dataset[i][list2]))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total PoI emails list\n",
    "poi_emails_list = get_total_list('from_this_person_to_poi', 'from_poi_to_this_person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total emails list\n",
    "total_emails_list = get_total_list('to_messages', 'from_messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides one list by another list\n",
    "def fraction_list(list1, list2):\n",
    "    new_list = []\n",
    "    for i in range(0,len(list1)):\n",
    "        if list2[i] == 0.0:\n",
    "            new_list.append(0.0)\n",
    "        else:\n",
    "            new_list.append(float(list1[i])/float(list2[i]))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting new list by dividing previously created lists\n",
    "fraction_poi_emails = fraction_list(poi_emails_list, total_emails_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding this new feature to the dataset\n",
    "count = 0\n",
    "for i in my_dataset:\n",
    "    my_dataset[i]['fraction_poi_emails'] = fraction_poi_emails[count]\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['to_messages', 'deferral_payments', 'expenses', 'poi', 'deferred_income', 'email_address', 'long_term_incentive', 'restricted_stock_deferred', 'from_messages', 'shared_receipt_with_poi', 'loan_advances', 'fraction_poi_emails', 'other', 'director_fees', 'bonus', 'total_stock_value', 'from_poi_to_this_person', 'from_this_person_to_poi', 'restricted_stock', 'salary', 'total_payments', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "# printing all features\n",
    "print len((my_dataset['SKILLING JEFFREY K'].keys()))\n",
    "print (my_dataset['SKILLING JEFFREY K'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Printing all features again, we can now see that there are 22 features, as 'fraction_poi_emails' has been added to the list. Now we are going to add this new feature into the features_list.\n",
    "\n",
    "> However, the 'email_address' feature is actually unnecessary so we will remove that one from the feature list. There are still 22 features in the dataset, but we will only be using 21 of them for the rest of the analysis. This brings us back to 21 features, essentially replacing 'email_address' with 'fraction_poi_emails'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'fraction_poi_emails' to features_list, and removing 'email_address'\n",
    "features_list = [\n",
    " 'poi',\n",
    " 'bonus',\n",
    " 'deferral_payments',\n",
    " 'deferred_income',\n",
    " 'director_fees',\n",
    " 'exercised_stock_options',\n",
    " 'expenses',\n",
    " 'from_messages',\n",
    " 'from_poi_to_this_person',\n",
    " 'from_this_person_to_poi',\n",
    " 'loan_advances',\n",
    " 'long_term_incentive',\n",
    " 'other',\n",
    " 'restricted_stock',\n",
    " 'restricted_stock_deferred',\n",
    " 'salary',\n",
    " 'shared_receipt_with_poi',\n",
    " 'to_messages',\n",
    " 'total_payments',\n",
    " 'total_stock_value',\n",
    " 'fraction_poi_emails'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Best Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, we are going to run decision tree with the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7543859649122807\n",
      "Precision:  0.25\n",
      "Recall:  0.375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from time import time\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# features_list\n",
    "features_list = ['poi','salary', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# split data inton training and testing\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "\n",
    "# choose decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print 'Accuracy: ' + str(acc)\n",
    "print 'Precision: ', precision_score(labels_test, pred)\n",
    "print 'Recall: ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, we will run decision tree with the added feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7719298245614035\n",
      "Precision:  0.3076923076923077\n",
      "Recall:  0.5\n"
     ]
    }
   ],
   "source": [
    "# features_list\n",
    "features_list = ['poi','salary', 'from_poi_to_this_person', 'fraction_poi_emails', 'from_this_person_to_poi', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# split data inton training and testing\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "\n",
    "# choose decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print 'Accuracy: ' + str(acc)\n",
    "print 'Precision: ', precision_score(labels_test, pred)\n",
    "print 'Recall: ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adding the new feature improved the Accuracy, Precision and Recall scores. We will keep this added feature for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Best Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With our added feature, we improved all 3 of the performance scores, however there may be a better way to do this. We are going  to run Select K Best and choose the most important features from out dataset. We will then run decision tree again with the selected features and see if the performance has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features:  ['poi', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred', 'expenses', 'director_fees', 'deferred_income']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# features_list\n",
    "features_list = ['poi','salary', 'from_poi_to_this_person', 'fraction_poi_emails', 'from_this_person_to_poi', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# split data inton training and testing\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "selector = SelectKBest(k=10)\n",
    "selectedFeatures = selector.fit(features,labels)\n",
    "feature_names = [features_list[i] for i in selectedFeatures.get_support(indices=True)]\n",
    "print 'Best features: ', feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see here that the model has chosen the 10 best features. The feature that was created and added was not selected as a best feature. We are now going to run decision tree again with these selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8421052631578947\n",
      "Precision:  0.42857142857142855\n",
      "Recall:  0.375\n"
     ]
    }
   ],
   "source": [
    "# features_list\n",
    "features_list = ['poi', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred', 'expenses', 'director_fees', 'deferred_income']\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# split data inton training and testing\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "\n",
    "# choose decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print 'Accuracy: ' + str(acc)\n",
    "print 'Precision: ', precision_score(labels_test, pred)\n",
    "print 'Recall: ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Running decision tree with only the best selected features has actually improved all 3 scores quite significantly. Even more than running with the new feature that was created. We will continue using just these 10 best selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8771929824561403\n",
      "Precision:  0.6\n",
      "Recall:  0.375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "\n",
    "clf = NearestCentroid()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print 'Accuracy: ' + str(acc)\n",
    "print 'Precision: ', precision_score(labels_test, pred)\n",
    "print 'Recall: ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7543859649122807\n",
      "Precision:  0.2857142857142857\n",
      "Recall:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print 'Accuracy: ' + str(acc)\n",
    "print 'Precision: ', precision_score(labels_test, pred)\n",
    "print 'Recall: ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8771929824561403\n",
      "Precision:  0.6\n",
      "Recall:  0.375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print 'Accuracy: ' + str(acc)\n",
    "print 'Precision: ', precision_score(labels_test, pred)\n",
    "print 'Recall: ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Out of all the algorithms, Logistic Regression with the selected features has the highest overall accuracy, precision, and recall scores. We will now try to tune to achieve even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJ\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print \"Best estimator found by grid search:\"\n",
    "print clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8771929824561403\n",
      "Precision:  0.6\n",
      "Recall:  0.375\n"
     ]
    }
   ],
   "source": [
    "# features_list\n",
    "features_list = ['poi', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred', 'expenses', 'director_fees', 'deferred_income']\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# split data inton training and testing\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "\n",
    "clf = LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print 'Accuracy: ' + str(acc)\n",
    "print 'Precision: ', precision_score(labels_test, pred)\n",
    "print 'Recall: ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tuning the parameters according to GridSearchCV still results in the original performance of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dumping classifier, dataset, and features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The goal of this project was to create a PoI identifier based on public Enron financial and email data. This can be created by finding the attributes that PoI have in common, and attributes that non PoIs have in common. Loading these into a machine learning algorithm, and the algorithm can try to detect who might be a PoI and who might not. There were several outliers that had to be removed, such as data in the wrong place, and a total summary of all data that was not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The feature I created was the percentage of PoI emails to other PoIs, compared the the total emails from anyone to anyone. This caused the algorithm to have better performance than just using the original features. However, I then used selectkbest to choose the most optimal features to use and the feature I added was not chosen. Using the selected features caused the algorithm to have even better performance than when using the feature I created, so I used the features from selectKBest and did not add any others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The algorithm with the highest overall scores was the Logistic Regression model. After comparing several algorithms with the selected features, Logistic Regression had the best overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well? How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> An algorithms parameters must be tuned to a certain extent. Too much or too little can lead to innacurate data and overfitting. The model was originally tuned by using SelectKBest. This chose the most optimal features to use, while getting rid of features that would only negatively affect performance. I then used GridSearchCV to find the most optimal parameters for the Logistic Regression model. Another form of tuning is Feature Scaling. The model I used, Logistic Regression, does not require feature scaling, so it was not used. However, in a model that does require feature scaling, it is necessary to use. Not using feature scaling can cause some features to have too much weight and some to not have enough. This can cause the data to become very skewed in one direction because of the weight of a certain feature. Feature scaling is necessary to manage the weights of all features and balance them as well as possible to obtain the most accurate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Validation is the processed of checking to see how your model performs on unseen data. A classic mistake would be tuning your model be able to predict your training data very well , but then having it perform poorly on unseen out-of-sample testing data. This is called overfitting. One of the major goals in validation is to avoid overfitting, which can be accomplished through a process called cross-validation. This analysis was validated though Sklearns Train/Test/Split algorithm. This splits the data into both training and testing data to be used to train and test the algorithms and compare their performance to the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give at least 2 evaluation metrics and your average performance for each of them. Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Logistic Regression with the specific features and tuned parameters was able to get an Accuracy score of ~ 87.7%, a Precision score of 60%, and a Recall score of ~ 37.5%. These scores, specifially the accuracy score, gives about a 87% chance for the algorithm to essentially guess who might be a PoI and who might not. This is significantly better than just guessing who might be a PoI by random selection of any of the 146 original people in the dataset, which would be more like less than 1% chance of a correct guess, based on no further information. However, by training the algorithm, it can achieve a fairly high accuracy in choosing who is a PoI and who is not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
